{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Details\n",
    "## Group Name:\n",
    "### Student 1:\n",
    "### Student 2:\n",
    "### Student 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available, else use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "TRAIN = False\n",
    "GRID_SEARCH = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "def load_trajectory(filename, task):\n",
    "    \"\"\"\n",
    "    This function loads a trajectory from a given file and returns the trajectory and energy data. \n",
    "    If the task is 'task_3', it also returns the framework data.\n",
    "\n",
    "    Parameters:\n",
    "    filename (str): The name of the file from which to load the trajectory.\n",
    "    task (str): The task for which the trajectory is being loaded. \n",
    "                This should be one of 'task_1', 'task_2', or 'task_3'.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Depending on the task, the function returns:\n",
    "           - (trajectory, energy) for 'task_1' and 'task_2'\n",
    "           - (trajectory, framework, energy) for 'task_3'\n",
    "    \"\"\"\n",
    "    traj = np.load(filename)\n",
    "    if task == 'task_1' or task == 'task_2':\n",
    "        trajectory = traj['trajectory']\n",
    "        energy = traj['energy']\n",
    "        return trajectory, energy\n",
    "    if task == 'task_3':\n",
    "        trajectory = traj['trajectory']\n",
    "        framework = traj['framework']\n",
    "        energy = traj['energy']\n",
    "        return trajectory, framework, energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, you can find an example of how to load a trajectory. ```trajectory``` contains the particle position, velocity and charge data. ```energy``` contains the energy of the system at various timesteps. The shape of the arrays is as follows:\n",
    "\n",
    "```trajectory```: ```(time, n_bodies, [x, y, v_x, v_y, q])```\n",
    "\n",
    "```energy```: ```(time, 1)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "trajectory, energy = load_trajectory('data/task1_2/train/trajectory_0.npz', 'task_1')\n",
    "print(f'Trajectory shape: {trajectory.shape}, Energy shape: {energy.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "x_0 = trajectory[0][0][0]\n",
    "y_0 = trajectory[0][0][1]\n",
    "print(f'Initial position: {x_0}, {y_0} Blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code provides an example of how to visualize a trajectory. Feel free to modify this code, or write your own function. When evaluating your model in task 2 and 3, keep in mind that you are only allowed to use the data at t=0 (the black dots in the visualization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "def plot_trajectory_energy(trajectory, energy):\n",
    "    \"\"\"\n",
    "    This function plots the trajectory of a system and its energy over time.\n",
    "\n",
    "    Parameters:\n",
    "    trajectory (numpy.ndarray): A 2D array representing the trajectory of the system. \n",
    "                                The first dimension represents time, and the second dimension represents the x and y coordinates.\n",
    "    energy (numpy.ndarray): A 1D array representing the energy of the system at each time step.\n",
    "\n",
    "    The function first plots the trajectory on a 2D grid, with the x and y coordinates on the x and y axes respectively. \n",
    "    The initial position is marked in black. The trajectory is represented by a scatter plot, with each point representing the position at a different time step.\n",
    "\n",
    "    Then, the function plots the energy of the system over time on a separate graph. The x-axis represents the time step, and the y-axis represents the energy.\n",
    "    \"\"\"\n",
    "    \n",
    "    x = trajectory[...,0]\n",
    "    y = trajectory[...,1]\n",
    "\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.vlines([0,20],0,20)\n",
    "    plt.hlines([0,20],0,20)\n",
    "\n",
    "    plt.scatter(x[0], y[0], c='black')\n",
    "\n",
    "    for i in range(x.shape[1]):\n",
    "        plt.scatter(x[:,i], y[:,i], s=5)\n",
    "\n",
    "    plt.xlim(-1,21)\n",
    "    plt.ylim(-1,21)\n",
    "\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(4,1))\n",
    "    plt.plot(energy)\n",
    "    plt.xlabel('step')\n",
    "    plt.title('System energy over time')\n",
    "    plt.show();\n",
    "\n",
    "plot_trajectory_energy(trajectory, energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement task 1 below. Feel free to add extra code cells for different components of your implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "def minimum_image_distance(pos1, pos2, box_length):\n",
    "    \"\"\"\n",
    "    Compute the distance between two points with the minimum image convention.\n",
    "\n",
    "    Parameters:\n",
    "    pos1, pos2: numpy arrays representing the positions of the two points.\n",
    "    box_length: float representing the length of one side of the box.\n",
    "\n",
    "    Returns:\n",
    "    float representing the distance between the two points.\n",
    "    \"\"\"\n",
    "    delta = pos2 - pos1\n",
    "    delta = delta - box_length * np.round(delta / box_length)\n",
    "    return np.sqrt(np.sum(delta**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "def create_graph_from_particles(particles, energy, box_length=20.0, cutoff_value=10.0, task='task_1'):\n",
    "    \"\"\"\n",
    "    This function creates a graph representation of a system of particles for use in graph neural networks. \n",
    "    Each particle is represented as a node in the graph, and edges are created between particles that are within a certain cutoff distance of each other.\n",
    "\n",
    "    Parameters:\n",
    "    particles (numpy.ndarray): A 2D array representing the particles in the system. \n",
    "                               Each row represents a particle, with the first two columns representing the x and y coordinates of the particle, \n",
    "                               and the remaining columns representing additional features of the particle.\n",
    "    energy (float): The energy of the system.\n",
    "    box_length (float, optional): The length of the box in which the particles are contained. \n",
    "                                  This is used to calculate the minimum image distance between particles. Defaults to 20.0.\n",
    "    cutoff_value (float, optional): The maximum distance at which two particles are considered to be connected by an edge. Defaults to 10.0.\n",
    "\n",
    "    Returns:\n",
    "    torch_geometric.data.Data: A Data object representing the graph. \n",
    "                               The node features, edge indices, edge attributes, and energy are stored as attributes of this object.\n",
    "\n",
    "    The function first creates a list of node features and a list of edge indices and attributes. \n",
    "    Then, it converts these lists into PyTorch tensors and creates a Data object from them. \n",
    "    Finally, it validates the Data object to ensure that it is correctly formatted.\n",
    "    \"\"\"\n",
    "\n",
    "    if task == 'task_1':\n",
    "        num_particles = particles.shape[0]\n",
    "        x = particles[:, 2:] # Position is not used as node feature\n",
    "\n",
    "        edge_index = []\n",
    "        edge_attr = []\n",
    "        for i in range(num_particles):\n",
    "            for j in range(num_particles):\n",
    "                if i != j:  # Avoid self-loops\n",
    "\n",
    "                    # Append edge if distance is below cutoff\n",
    "                    pos1 = particles[i, :2]\n",
    "                    pos2 = particles[j, :2]\n",
    "                    distance = minimum_image_distance(pos1, pos2, box_length)\n",
    "                    \n",
    "                    edge_index.append([i, j])\n",
    "                    if distance < cutoff_value: # TODO Per essere corretto non bisognerebbe creare l'edge se la distanza è maggiore del cutoff, ma facendo cosi ci sono errori in alcuni casi limite (annuncio canvas). Ho messo quindi rami con pesi negativi (distanze) per gli edge che non dovrebbero esistere. In questo modo il modello dovrebbe imparare a non considerarli.\n",
    "                        edge_attr.append(distance)\n",
    "                    else:\n",
    "                        edge_attr.append(-1.0) # Use -1.0 as padding value\n",
    "\n",
    "        x = torch.tensor(x, dtype=torch.float)         \n",
    "        edge_index = torch.tensor(edge_index).t().contiguous()\n",
    "        edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "        energy = torch.tensor(energy, dtype=torch.float)\n",
    "\n",
    "        # Create Data object\n",
    "        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=energy)\n",
    "\n",
    "        # Validate data object\n",
    "        data.validate(raise_on_error=True)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    elif task == 'task_2':\n",
    "\n",
    "        num_particles = particles.shape[0]\n",
    "\n",
    "        x = particles[:, :] # Position is used as node feature\n",
    "        energies = np.array([energy]*num_particles)\n",
    "        # Concatenate energy to node features\n",
    "        # x = np.concatenate((x, energies), axis=1) # TODO check\n",
    "\n",
    "        edge_index = []\n",
    "        edge_attr = []\n",
    "        for i in range(num_particles):\n",
    "            for j in range(num_particles):\n",
    "                if i != j:  # Avoid self-loops\n",
    "\n",
    "                    # Append edge if distance is below cutoff\n",
    "                    pos1 = particles[i, :2]\n",
    "                    pos2 = particles[j, :2]\n",
    "                    distance = minimum_image_distance(pos1, pos2, box_length)\n",
    "                    \n",
    "                    edge_index.append([i, j])\n",
    "                    if distance < cutoff_value: # TODO Per essere corretto non bisognerebbe creare l'edge se la distanza è maggiore del cutoff, ma facendo cosi ci sono errori in alcuni casi limite (annuncio canvas). Ho messo quindi rami con pesi negativi (distanze) per gli edge che non dovrebbero esistere. In questo modo il modello dovrebbe imparare a non considerarli.\n",
    "                        edge_attr.append(distance)\n",
    "                    else:\n",
    "                        edge_attr.append(-1.0) # Use -1.0 as padding value\n",
    "\n",
    "        x = torch.tensor(x, dtype=torch.float)         \n",
    "        edge_index = torch.tensor(edge_index).t().contiguous()\n",
    "        edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "        energy = torch.tensor(energy, dtype=torch.float)\n",
    "\n",
    "        # Create Data object\n",
    "        # data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "        data = Data(x=x, edge_index=edge_index) # TODO add also edge_attr\n",
    "\n",
    "        # Validate data object\n",
    "        data.validate(raise_on_error=True)\n",
    "        \n",
    "        return data\n",
    "\n",
    "\n",
    "def create_particle_data_list(trajectory, energies, box_length=20.0, cutoff_value=10.0):\n",
    "    \"\"\"\n",
    "    This function creates a list of graph representations of a system of particles for each time step in a trajectory. \n",
    "    Each particle is represented as a node in the graph, and edges are created between particles that are within a certain cutoff distance of each other.\n",
    "\n",
    "    Parameters:\n",
    "    trajectory (numpy.ndarray): A 3D array representing the trajectory of the system. \n",
    "                                The first dimension represents time, the second dimension represents particles, \n",
    "                                and the third dimension represents the x and y coordinates of the particles.\n",
    "    energies (numpy.ndarray): A 1D array representing the energy of the system at each time step.\n",
    "    box_length (float, optional): The length of the box in which the particles are contained. \n",
    "                                  This is used to calculate the minimum image distance between particles. Defaults to 20.0.\n",
    "    cutoff_value (float, optional): The maximum distance at which two particles are considered to be connected by an edge. Defaults to 10.0.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of PyTorch Geometric Data objects, each representing the graph of the system at a different time step.\n",
    "\n",
    "    The function iterates over each time step in the trajectory, creating a graph for each one and appending it to the list. \n",
    "    The graphs are created using the create_graph_from_particles function.\n",
    "    \"\"\"\n",
    "    particle_data_list = []\n",
    "    for i in range(trajectory.shape[0]):\n",
    "        particles = trajectory[i]\n",
    "        energy = energies[i]\n",
    "        particle_data_list.append(create_graph_from_particles(particles, energy, box_length, cutoff_value))\n",
    "    return particle_data_list\n",
    "\n",
    "particle_data_list = create_particle_data_list(trajectory, energy)\n",
    "particles = trajectory[0]\n",
    "particles_graph = particle_data_list[0]\n",
    "print(f'Particles ({particles.shape}):\\n {particles}')\n",
    "print(f'Particles graph:\\n {particles_graph}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def visualize_graph(data):\n",
    "    \"\"\"\n",
    "    This function visualizes a graph represented by a PyTorch Geometric Data object using NetworkX and Matplotlib.\n",
    "\n",
    "    Parameters:\n",
    "    data (torch_geometric.data.Data): A Data object representing the graph. \n",
    "                                      The node features, edge indices, and edge attributes are stored as attributes of this object.\n",
    "\n",
    "    The function first creates a NetworkX DiGraph object and adds nodes and edges to it based on the edge indices and edge attributes in the Data object. \n",
    "    The edges are weighted based on the edge attributes.\n",
    "\n",
    "    Then, the function uses NetworkX's spring layout algorithm to calculate the positions of the nodes, and draws the nodes, edges, and labels using Matplotlib.\n",
    "\n",
    "    Finally, the function displays the graph using Matplotlib's pyplot.show() function.\n",
    "    \"\"\"\n",
    "    edge_index = data.edge_index.cpu().numpy()\n",
    "    edge_attr = data.edge_attr.cpu().numpy() \n",
    "    num_nodes = data.x.shape[0]\n",
    "\n",
    "    # Create a networkx graph\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Add nodes\n",
    "    for i in range(num_nodes):\n",
    "        G.add_node(i)\n",
    "\n",
    "    # Add edges with weights\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        src, dst = edge_index[:, i]\n",
    "        weight = edge_attr[i] \n",
    "        G.add_edge(src, dst, weight=weight)\n",
    "\n",
    "    # Draw the graph\n",
    "    pos = nx.spring_layout(G)  # positions for all nodes\n",
    "\n",
    "    # nodes\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=700)\n",
    "\n",
    "    # edges\n",
    "    nx.draw_networkx_edges(G, pos, width=6)\n",
    "\n",
    "    # labels\n",
    "    nx.draw_networkx_labels(G, pos, font_size=20, font_family='sans-serif')\n",
    "\n",
    "    # edge labels\n",
    "    edge_labels = dict([((u, v,), d['weight'])\n",
    "                        for u, v, d in G.edges(data=True)])\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
    "\n",
    "    plt.axis('on')\n",
    "    plt.show()\n",
    "\n",
    "visualize_graph(particles_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# Compute distances between all pairs of nodes\n",
    "def compute_distances(particles, box_length=20):\n",
    "    \"\"\"\n",
    "    This function computes the distances between all pairs of particles in a system, taking into account the periodic boundary conditions of the system.\n",
    "\n",
    "    Parameters:\n",
    "    particles (numpy.ndarray): A 2D array representing the particles in the system. \n",
    "                               Each row represents a particle, with the first two columns representing the x and y coordinates of the particle.\n",
    "    box_length (float, optional): The length of the box in which the particles are contained. \n",
    "                                  This is used to calculate the minimum image distance between particles. Defaults to 20.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: A 2D array representing the distance between each pair of particles. \n",
    "                   The element at the i-th row and j-th column represents the distance between the i-th and j-th particles.\n",
    "\n",
    "    The function first initializes a 2D array of zeros with a size equal to the number of particles. \n",
    "    Then, it iterates over each pair of particles, calculates the minimum image distance between them, \n",
    "    and stores the result in the corresponding element of the distance array. \n",
    "    Since the distance between the i-th and j-th particles is the same as the distance between the j-th and i-th particles, \n",
    "    the function only calculates the distance once for each pair of particles.\n",
    "    \"\"\"\n",
    "    num_particles = len(particles)\n",
    "    distances = np.zeros((num_particles, num_particles))\n",
    "\n",
    "    for i in range(num_particles):\n",
    "        pos_1 = particles[i, :2]\n",
    "        for j in range(i+1, num_particles):\n",
    "            pos_2 = particles[j, :2]\n",
    "            distances[i, j] = minimum_image_distance(pos_1, pos_2, box_length)\n",
    "            distances[j, i] = distances[i, j]  # The distance matrix is symmetric\n",
    "\n",
    "    return distances\n",
    "\n",
    "particles = trajectory[0]\n",
    "distances = compute_distances(particles)\n",
    "distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ParticleDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset for representing a system of particles. \n",
    "    The dataset is created from a list of file paths, each of which contains a trajectory of the system.\n",
    "\n",
    "    Attributes:\n",
    "    file_paths (list): A list of file paths from which to load the trajectories.\n",
    "    task (str): The task for which the dataset is being created. This should be one of 'task_1', 'task_2', or 'task_3'.\n",
    "    max_len (int): The maximum number of particles in the system.\n",
    "    box_length (float, optional): The length of the box in which the particles are contained. Defaults to 20.0.\n",
    "    cutoff (float, optional): The maximum distance at which two particles are considered to be connected by an edge. Defaults to 10.0.\n",
    "    data_list (list): A list of PyTorch Geometric Data objects, each representing the graph of the system at a different time step.\n",
    "    \"\"\"\n",
    "    def __init__(self, file_paths, task, max_len, box_length=20.0, cutoff=10.0):\n",
    "        \"\"\"\n",
    "        Initializes the ParticleDataset with the given file paths, task, maximum number of particles, box length, and cutoff distance.\n",
    "        \"\"\"\n",
    "        self.file_paths = file_paths\n",
    "        self.task = task\n",
    "        self.max_len = max_len\n",
    "        self.box_length = box_length\n",
    "        self.cutoff = cutoff\n",
    "        self.data_list = []\n",
    "        for file_path in tqdm(file_paths):\n",
    "            if task == 'task_1' or task == 'task_2':\n",
    "                trajectory, energy = load_trajectory(file_path, task)\n",
    "                particle_data_list = create_particle_data_list(trajectory, energy, self.box_length, self.cutoff)\n",
    "            elif task == 'task_3':\n",
    "                trajectory, framework, energy = load_trajectory(file_path, task)\n",
    "                particle_data_list = create_particle_data_list(trajectory, energy, self.box_length, self.cutoff)\n",
    "            self.data_list += particle_data_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the length of the dataset, i.e., the number of time steps in all trajectories.\n",
    "        \"\"\"\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns the Data object at the given index.\n",
    "        \"\"\"\n",
    "        return self.data_list[idx]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "\n",
    "# Define the paths and parameters\n",
    "file_paths = glob.glob('data/task1_2/train/*.npz')\n",
    "\n",
    "max_len = 40  # The maximum length of the trajectories is 40\n",
    "box_length = 20.0  # The length of the simulation box\n",
    "cutoff = 10.0  # The cutoff distance for the edges\n",
    "task = 'task_1'  # The task to perform\n",
    "batch_size = 1  # The batch size\n",
    "\n",
    "train_file_paths, val_file_paths = train_test_split(file_paths, test_size=0.2, random_state=0)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = ParticleDataset(train_file_paths, task, max_len, box_length, cutoff)\n",
    "val_dataset = ParticleDataset(val_file_paths, task, max_len, box_length, cutoff)\n",
    "\n",
    "print(f'Train dataset: {len(train_dataset)} samples')\n",
    "print(f'Validation dataset: {len(val_dataset)} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for data in train_loader:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Node_to_emb(nn.Module):\n",
    "    \"\"\"\n",
    "    This class is a PyTorch module that transforms node features into node embeddings using a linear transformation.\n",
    "\n",
    "    Attributes:\n",
    "    emb (nn.Linear): A linear transformation layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, node_feat_dim=5, node_emb_dim=64):\n",
    "        \"\"\"\n",
    "        Initializes the Node_to_emb with the given dimensions for the node features and node embeddings.\n",
    "        \"\"\"\n",
    "        super(Node_to_emb, self).__init__()\n",
    "        self.emb = nn.Linear(node_feat_dim, node_emb_dim)\n",
    "\n",
    "    def forward(self, nodes):\n",
    "        \"\"\"\n",
    "        Transforms the given node features into node embeddings using the linear transformation layer.\n",
    "        \"\"\"\n",
    "        assert nodes.size(-1) == self.emb.in_features, 'wrong input dimension of node features!'\n",
    "        return self.emb(nodes)\n",
    "\n",
    "class MpLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    This class is a PyTorch module that represents a message passing layer in a graph neural network.\n",
    "\n",
    "    Attributes:\n",
    "    edge_network (nn.Sequential): A sequence of layers that transform the edge features.\n",
    "    node_network (nn.Sequential): A sequence of layers that transform the node features.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim, activation=nn.ReLU()):\n",
    "        \"\"\"\n",
    "        Initializes the MpLayer with the given hidden dimension and activation function.\n",
    "        \"\"\"\n",
    "        super(MpLayer, self).__init__()\n",
    "        self.edge_network = nn.Sequential(\n",
    "            nn.Linear(2*hidden_dim + 1, hidden_dim),\n",
    "            activation,\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            activation\n",
    "        )\n",
    "        self.node_network = nn.Sequential(\n",
    "            nn.Linear(2*hidden_dim, hidden_dim),\n",
    "            activation,\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, node_tensor, edge_idx_tensor, edge_attr_tensor):\n",
    "        \"\"\"\n",
    "        Performs the forward pass of the message passing layer.\n",
    "        \"\"\"\n",
    "        edge_messages_input = torch.cat([node_tensor[edge_idx_tensor[0,:]], node_tensor[edge_idx_tensor[1,:]]], dim=-1)\n",
    "        \n",
    "        if edge_attr_tensor is not None:\n",
    "            edge_attr_tensor = edge_attr_tensor.unsqueeze(-1)\n",
    "            edge_messages_input = torch.cat([edge_messages_input, edge_attr_tensor], dim=-1)\n",
    "        \n",
    "        edge_messages_output = self.edge_network(edge_messages_input)\n",
    "        \n",
    "        node_agg_messages = torch.zeros_like(node_tensor).to(node_tensor.device)\n",
    "        node_agg_messages = node_agg_messages.scatter_add_(\n",
    "            dim=0, index=edge_idx_tensor[1].unsqueeze(-1).expand(-1, node_tensor.size(1)), src=edge_messages_output\n",
    "        )\n",
    "        \n",
    "        node_out = self.node_network(torch.cat([node_tensor, node_agg_messages], dim=-1))\n",
    "        return node_out, edge_idx_tensor\n",
    "\n",
    "class MpGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    This class is a PyTorch module that represents a message passing graph neural network.\n",
    "\n",
    "    Attributes:\n",
    "    node_to_emb (Node_to_emb): A module that transforms node features into node embeddings.\n",
    "    mp_layers (nn.ModuleList): A list of message passing layers.\n",
    "    to_pred (nn.Linear): A linear transformation layer that transforms the output of the last message passing layer into the final output.\n",
    "    \"\"\"\n",
    "    def __init__(self, node_feat_dim, hidden_dim, activation=nn.ReLU(), num_layers=3):\n",
    "        \"\"\"\n",
    "        Initializes the MpGNN with the given dimensions for the node features and hidden layer, activation function, and number of layers.\n",
    "        \"\"\"\n",
    "        super(MpGNN, self).__init__()\n",
    "        self.node_to_emb = Node_to_emb(node_feat_dim, hidden_dim)\n",
    "        self.mp_layers = nn.ModuleList([MpLayer(hidden_dim, activation) for _ in range(num_layers)])\n",
    "        self.to_pred = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        \"\"\"\n",
    "        Performs the forward pass of the graph neural network.\n",
    "        \"\"\"\n",
    "        x = self.node_to_emb(x)\n",
    "        for layer in self.mp_layers:\n",
    "            x, edge_index = layer(x, edge_index, edge_attr)\n",
    "        \n",
    "        out = torch.zeros(batch.max().item() + 1, x.size(1)).to(x.device)\n",
    "        idx_aggregate_graph = batch.unsqueeze(-1).expand_as(x)\n",
    "        out.scatter_add_(dim=0, index=idx_aggregate_graph, src=x)\n",
    "        \n",
    "        out = self.to_pred(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "num_features = int(train_dataset[0].x.shape[1])\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "hidden_dim = 64\n",
    "num_layers = 7\n",
    "learning_rate = 0.0001\n",
    "weight_decay = 0\n",
    "num_epochs = 20\n",
    "\n",
    "# Initialize the model, optimizer and loss function\n",
    "model = MpGNN(num_features, hidden_dim=hidden_dim, num_layers=num_layers) # initialize our GNN\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "model.to(device)  # and move to the GPU, if possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    \"\"\"\n",
    "    This function trains the given model for one epoch using the given data loader, optimizer, loss function, and device.\n",
    "\n",
    "    Parameters:\n",
    "    model (torch.nn.Module): The model to train.\n",
    "    train_loader (torch.utils.data.DataLoader): The data loader that provides the training data.\n",
    "    optimizer (torch.optim.Optimizer): The optimizer to use for training.\n",
    "    criterion (torch.nn.Module): The loss function to use for training.\n",
    "    device (torch.device): The device to use for training.\n",
    "\n",
    "    The function first sets the model to training mode. Then, it iterates over the training data. For each batch of data, \n",
    "    it moves the data to the given device, performs a forward pass, computes the loss, performs a backward pass, \n",
    "    and updates the model parameters. The function keeps track of the total loss over all batches. \n",
    "    Finally, it returns the average loss over all batches.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        \n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "       \n",
    "        loss = criterion(output, data.y.view(-1, 1))  # y is a single value per graph\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    This function validates the given model using the given data loader, loss function, and device.\n",
    "\n",
    "    Parameters:\n",
    "    model (torch.nn.Module): The model to validate.\n",
    "    val_loader (torch.utils.data.DataLoader): The data loader that provides the validation data.\n",
    "    criterion (torch.nn.Module): The loss function to use for validation.\n",
    "    device (torch.device): The device to use for validation.\n",
    "\n",
    "    The function first sets the model to evaluation mode. Then, it iterates over the validation data. \n",
    "    For each batch of data, it moves the data to the given device, performs a forward pass, and computes the loss. \n",
    "    The function keeps track of the total loss over all batches. \n",
    "    Finally, it returns the average loss over all batches.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "            loss = criterion(output, data.y.view(-1, 1))  # y is a single value per graph\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "# Train model\n",
    "if TRAIN:\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # Initialize best validation loss to infinity\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "        train_losses.append(train_loss)\n",
    "        val_loss = validate(model, val_loader, criterion, device)\n",
    "        val_losses.append(val_loss)\n",
    "        print(f'Epoch {epoch+1}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n",
    "\n",
    "        # Save the model if it's the best one so far\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "    print(f'Best Val Loss: {best_val_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# Plot the training and validation losses\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    \"\"\"\n",
    "    This function plots the training and validation losses over epochs.\n",
    "\n",
    "    Parameters:\n",
    "    train_losses (list): A list of training losses for each epoch.\n",
    "    val_losses (list): A list of validation losses for each epoch.\n",
    "\n",
    "    The function uses matplotlib to create a line plot of the training and validation losses. \n",
    "    The x-axis represents the epoch number and the y-axis represents the loss. \n",
    "    The training losses are plotted in one color and the validation losses are plotted in another color. \n",
    "    A legend is added to the plot to distinguish between the two lines. \n",
    "    Finally, the plot is displayed.\n",
    "    \"\"\"\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "if TRAIN:\n",
    "    plot_losses(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "model = MpGNN(num_features, hidden_dim=hidden_dim, num_layers=num_layers)\n",
    "model.load_state_dict(torch.load('best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# Load and preprocess test data\n",
    "test_file_paths = glob.glob('data/task1_2/test/*.npz')\n",
    "\n",
    "test_dataset = ParticleDataset(test_file_paths, task, max_len, box_length, cutoff)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "print(f'Test dataset: {len(test_dataset)} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "def compute_test_loss(model, test_loader, criterion):\n",
    "    \"\"\"\n",
    "    This function computes the loss of the given model on the given test data using the given loss function.\n",
    "\n",
    "    Parameters:\n",
    "    model (torch.nn.Module): The model to test.\n",
    "    test_loader (torch.utils.data.DataLoader): The data loader that provides the test data.\n",
    "    criterion (torch.nn.Module): The loss function to use for testing.\n",
    "\n",
    "    The function first sets the model to evaluation mode. Then, it iterates over the test data. \n",
    "    For each batch of data, it moves the data to the device, performs a forward pass, and computes the loss. \n",
    "    The function keeps track of the total loss over all batches. Finally, it returns the average loss over all batches.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "            loss = criterion(output, data.y.view(-1, 1))  # y is a single value per graph\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(test_loader)\n",
    "\n",
    "compute_test_loss(model, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Batch\n",
    "\n",
    "def plot_predictions(model, file_paths, device, task, num_plots=5, box_length=20.0, cutoff_value=10.0):\n",
    "    \"\"\"\n",
    "    This function plots the predicted and true energies over time for a random selection of systems from the given file paths.\n",
    "\n",
    "    Parameters:\n",
    "    model (torch.nn.Module): The model to use for prediction.\n",
    "    file_paths (list): A list of file paths to the system data.\n",
    "    device (torch.device): The device to use for prediction.\n",
    "    task (str): The task to perform (e.g., 'classification', 'regression').\n",
    "    num_plots (int, optional): The number of plots to create. Default is 5.\n",
    "    box_length (float, optional): The length of the box in which the particles are contained. Default is 20.0.\n",
    "    cutoff_value (float, optional): The cutoff value for the interaction between particles. Default is 10.0.\n",
    "\n",
    "    The function first sets the model to evaluation mode. Then, it selects a random subset of the file paths. \n",
    "    For each selected file path, it loads the system data, creates a graph from the system data, \n",
    "    and uses the model to predict the energies of the system over time. \n",
    "    It then plots the predicted energies and the true energies on the same plot. \n",
    "    The x-axis represents the time step and the y-axis represents the energy. \n",
    "    A legend is added to the plot to distinguish between the predicted and true energies. \n",
    "    Finally, the function displays all the plots.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    random_indices = np.random.randint(0, len(file_paths), size=num_plots)\n",
    "    random_paths = [file_paths[i] for i in random_indices]\n",
    "\n",
    "    fig, axs = plt.subplots(num_plots, 1, figsize=(5, num_plots*2))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        plot_count = 0\n",
    "        for i, path in enumerate(random_paths):\n",
    "            \n",
    "            trajectory, energy = load_trajectory(path, task)\n",
    "           \n",
    "            # Create a graph from the trajectory\n",
    "            particles_list = create_particle_data_list(trajectory, energy, box_length, cutoff_value)\n",
    "            batched_data = Batch.from_data_list(particles_list).to(device)\n",
    "\n",
    "            output = model(batched_data.x, batched_data.edge_index, batched_data.edge_attr, batched_data.batch)\n",
    "\n",
    "            # Plot predicted energies\n",
    "            axs[plot_count].plot(output.cpu(), label='Predicted Energy')\n",
    "\n",
    "            # Plot true energies\n",
    "            axs[plot_count].plot(energy.flatten(), label='True Energy')\n",
    "\n",
    "            axs[plot_count].set_xlabel('step')\n",
    "            axs[plot_count].set_title('System energy over time')\n",
    "            axs[plot_count].legend()\n",
    "\n",
    "            \n",
    "            plot_count += 1\n",
    "            if plot_count == num_plots:\n",
    "                break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_predictions(model, test_file_paths, device, task)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def grid_search(train_loader, val_loader, num_features, num_epochs, device, output_file):\n",
    "    \"\"\"\n",
    "    This function performs a grid search over a set of hyperparameters to find the best model for the given training and validation data.\n",
    "\n",
    "    Parameters:\n",
    "    train_loader (torch.utils.data.DataLoader): The data loader that provides the training data.\n",
    "    val_loader (torch.utils.data.DataLoader): The data loader that provides the validation data.\n",
    "    num_features (int): The number of features in the input data.\n",
    "    num_epochs (int): The number of epochs to train each model.\n",
    "    device (torch.device): The device to use for training and validation.\n",
    "    output_file (str): The path to the file where the grid search results will be written.\n",
    "\n",
    "    The function iterates over all combinations of the hyperparameters. For each combination, it creates a model with the current hyperparameters, \n",
    "    trains the model for the given number of epochs, and computes the validation loss. \n",
    "    If the validation loss is lower than the best validation loss seen so far, the function updates the best model, best validation loss, and best hyperparameters. \n",
    "    The function writes the hyperparameters and validation loss of each model to the output file. \n",
    "    Finally, the function returns the best model, best hyperparameters, and best validation loss.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters to tune\n",
    "    hidden_dims = [32, 64, 128, 256]\n",
    "    num_layers_list = [5, 7, 9]\n",
    "    learning_rates = [0.0001, 0.001]\n",
    "    weight_decays = [0.0, 1e-5]\n",
    "\n",
    "    best_model = None\n",
    "    best_val_loss = float('inf')\n",
    "    best_params = {}\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(\"hidden_dim,num_layers,lr,weight_decay,val_loss\\n\")\n",
    "\n",
    "        for hidden_dim, num_layers, lr, weight_decay in tqdm(itertools.product(hidden_dims, num_layers_list, learning_rates, weight_decays)):\n",
    "            # Create model with current hyperparameters\n",
    "            model = MpGNN(num_features, hidden_dim=hidden_dim, num_layers=num_layers) # initialize our GNN\n",
    "            # Define optimizer and criterion\n",
    "            optimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "            criterion = torch.nn.MSELoss()\n",
    "\n",
    "            best_model_loss = float('inf')\n",
    "\n",
    "            # Train model\n",
    "            print(f'Starting training with hidden_dim={hidden_dim}, num_layers={num_layers}, lr={lr}, weight_decay={weight_decay}')\n",
    "            for epoch in range(num_epochs):\n",
    "                train_loss = train(model, train_loader, optimizer,criterion, device)\n",
    "                val_loss = validate(model, val_loader, criterion, device)\n",
    "                \n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    best_model = model\n",
    "                    best_params = {'hidden_dim': hidden_dim, 'num_layers': num_layers, 'lr': lr, 'weight_decay': weight_decay}\n",
    "                    torch.save(best_model.state_dict(), 'best_model_grid_search.pth')\n",
    "\n",
    "                if val_loss < best_model_loss:\n",
    "                    best_model_loss = val_loss\n",
    "\n",
    "            f.write(f\"{hidden_dim},{num_layers},{lr},{weight_decay},{best_model_loss}\\n\")\n",
    "            print(f\"Finished training with hidden_dim={hidden_dim}, num_layers={num_layers}, lr={lr}, weight_decay={weight_decay}, val_loss={best_model_loss}\")\n",
    "     \n",
    "    return best_model, best_params, best_val_loss\n",
    "\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "if GRID_SEARCH:\n",
    "    output_file = \"grid_search_results.txt\"\n",
    "    best_model, best_params, best_val_loss = grid_search(train_loader, val_loader, num_features, num_epochs, device, output_file)\n",
    "    torch.save(best_model.state_dict(), 'best_model_grid_search.pth')\n",
    "    print(\"Best Parameters:\")\n",
    "    print(best_params)\n",
    "    print(\"Best Validation Loss:\", best_val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Parameters: {'hidden_dim': 64, 'num_layers': 7, 'lr': 0.0001, 'weight_decay': 0}\n",
    "\n",
    "Best Validation Loss: 0.215618465204782"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement task 2 below. Feel free to add extra code cells for different components of your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "create_graph_from_particles(trajectory[0], energy[0], box_length=20.0, cutoff_value=10.0, task='task_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "def create_data_point(file_path, box_length=20.0, cutoff_value=10.0, task='task_2', max_len=40):\n",
    "    \"\"\"\n",
    "    This function creates a data point from a given trajectory and energy.\n",
    "\n",
    "    Parameters:\n",
    "    trajectory (numpy.ndarray): A 2D array representing the trajectory of the system. \n",
    "                                The first dimension represents time, and the second dimension represents the x and y coordinates of the particles.\n",
    "    energy (numpy.ndarray): A 1D array representing the energy of the system at each time step.\n",
    "    box_length (float, optional): The length of the box in which the particles are contained. Defaults to 20.0.\n",
    "    cutoff_value (float, optional): The maximum distance at which two particles are considered to be connected by an edge. Defaults to 10.0.\n",
    "\n",
    "    Returns:\n",
    "    torch_geometric.data.Data: A Data object representing the graph of the system at each time step.\n",
    "\n",
    "    The function first creates a list of PyTorch Geometric Data objects, each representing the graph of the system at a different time step. \n",
    "    Then, it returns the first element of the list, which corresponds to the first time step.\n",
    "    \"\"\"\n",
    "    trajectory, energy = load_trajectory(file_path, task)\n",
    "    \n",
    "    # Create Data object with position, velocity, charge and energy for each time step\n",
    "    data_point = []\n",
    "    for i in range(trajectory.shape[0]): # For each time step\n",
    "        particles = trajectory[i]\n",
    "        data_point.append(create_graph_from_particles(particles, energy[i], box_length, cutoff_value, task))\n",
    "            \n",
    "    return data_point\n",
    "\n",
    "data_point = create_data_point('data/task1_2/train/trajectory_0.npz')\n",
    "print(data_point[0])\n",
    "print(len(data_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "class TrajectoryDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset for representing a trajectory of a system of particles.\n",
    "\n",
    "    Attributes:\n",
    "    file_paths (list): A list of file paths from which to load the trajectories.\n",
    "    task (str): The task for which the dataset is being created. This should be one of 'task_1', 'task_2', or 'task_3'.\n",
    "    max_len (int): The maximum number of particles in the system.\n",
    "    box_length (float, optional): The length of the box in which the particles are contained. Defaults to 20.0.\n",
    "    cutoff (float, optional): The maximum distance at which two particles are considered to be connected by an edge. Defaults to 10.0.\n",
    "    data_list (list): A list of PyTorch Geometric Data objects, each representing the graph of the system at a different time step.\n",
    "    \"\"\"\n",
    "    def __init__(self, file_paths, task='task_2', max_len=40, box_length=20.0, cutoff=10.0):\n",
    "        \"\"\"\n",
    "        Initializes the TrajectoryDataset with the given file paths, task, maximum number of particles, box length, and cutoff distance.\n",
    "        \"\"\"\n",
    "        self.file_paths = file_paths\n",
    "        self.task = task\n",
    "        self.max_len = max_len\n",
    "        self.box_length = box_length\n",
    "        self.cutoff = cutoff\n",
    "        self.data_list = []\n",
    "        for file_path in tqdm(file_paths):\n",
    "            data_point = create_data_point(file_path, box_length, cutoff, task, max_len)\n",
    "            self.data_list.append(data_point)\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the length of the dataset, i.e., the number of time steps in all trajectories.\n",
    "        \"\"\"\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns the Data object at the given index.\n",
    "        \"\"\"\n",
    "        return self.data_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "\n",
    "# Define the paths and parameters\n",
    "file_paths = glob.glob('data/task1_2/train/*.npz')\n",
    "\n",
    "max_len = 40  # The maximum length of the trajectories is 40\n",
    "box_length = 20.0  # The length of the simulation box\n",
    "cutoff = 10.0  # The cutoff distance for the edges\n",
    "task = 'task_2'  # The task to perform\n",
    "\n",
    "train_file_paths, val_file_paths = train_test_split(file_paths, test_size=0.2, random_state=0)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TrajectoryDataset(train_file_paths, task, max_len, box_length, cutoff)\n",
    "val_dataset = TrajectoryDataset(val_file_paths, task, max_len, box_length, cutoff)\n",
    "\n",
    "print(f'Train dataset: {len(train_dataset)} samples')\n",
    "print(f'Validation dataset: {len(val_dataset)} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "print(train_dataset[0][0])\n",
    "len(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "print(val_dataset[0][0])\n",
    "len(val_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# from torch_geometric.data import Batch\n",
    "\n",
    "# def custom_collate_fn(batch):\n",
    "#     \"\"\"\n",
    "#     Custom collate function for batching lists of Data objects.\n",
    "#     \"\"\"\n",
    "#     batch_list = []\n",
    "\n",
    "#     for trajectory in batch:\n",
    "#         batch_list.append(Batch.from_data_list(trajectory))\n",
    "#     return batch_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# from torch_geometric.loader import DataLoader\n",
    "\n",
    "# # Create data loaders\n",
    "# batch_size = 2  # The batch size\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# # Iterazione sui batch\n",
    "# batch = next(iter(train_loader))\n",
    "# for trajectory in batch:\n",
    "#     print(trajectory)\n",
    "#     print(\"Batch size:\", trajectory.ptr.size(0) - 1)  # Numero di grafi nel batch\n",
    "#     print(\"Number of nodes in batch:\", trajectory.num_nodes)\n",
    "#     print(\"Number of edges in batch:\", trajectory.num_edges)\n",
    "#     print(trajectory.x)  # Caratteristiche dei nodi concatenate\n",
    "#     print(trajectory.edge_index)  # Indici degli archi concatenati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# from torch_geometric.loader import DataLoader\n",
    "\n",
    "# # Create data loaders\n",
    "# batch_size = 1\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# # Iterazione sui batch\n",
    "# batch = next(iter(train_loader))\n",
    "# for trajectory in batch:\n",
    "#     print(trajectory)\n",
    "#     print(\"Batch size:\", trajectory.ptr.size(0) - 1)  # Numero di grafi nel batch\n",
    "#     print(\"Number of nodes in batch:\", trajectory.num_nodes)\n",
    "#     print(\"Number of edges in batch:\", trajectory.num_edges)\n",
    "#     print(trajectory.x)  # Caratteristiche dei nodi concatenate\n",
    "#     print(trajectory.edge_index)  # Indici degli archi concatenati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# for data in train_loader:\n",
    "#     print(data)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esempio Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn.aggr import GRUAggregation\n",
    "\n",
    "class GraphPredictionModel(nn.Module):\n",
    "    def __init__(self, node_feature_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(GraphPredictionModel, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.gnn = GCNConv(node_feature_dim, hidden_dim)\n",
    "        # self.rnn = nn.GRU(hidden_dim, hidden_dim, num_layers)\n",
    "        self.rnn = GRUAggregation(hidden_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x, edge_index, h):\n",
    "\n",
    "        print(f\"input shape: {x.shape}\")\n",
    "\n",
    "        x = self.gnn(x, edge_index)\n",
    "        print(f\"gnn shape: {x.shape}\")\n",
    "\n",
    "        x, h = self.rnn(x.unsqueeze(0), h)\n",
    "        print(f\"rnn shape: {x.shape}\")\n",
    "        \n",
    "        x = self.fc(x.squeeze(0))\n",
    "        print(f\"output shape: {x.shape}\")\n",
    "        \n",
    "        return x, h\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.num_layers, batch_size, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# model = GraphPredictionModel(node_feature_dim=5, hidden_dim=64, output_dim=2, num_layers=2)\n",
    "# input = train_dataset[0][0]\n",
    "# print(input)\n",
    "# h = model.init_hidden(input.x.size(0))\n",
    "\n",
    "# summary(model, input.x, input.edge_index, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch_geometric.nn import GCNConv\n",
    "# from torch_geometric.data import Data\n",
    "\n",
    "# class GraphPredictionModel(nn.Module):\n",
    "#     def __init__(self, node_feature_dim, hidden_dim, output_dim):\n",
    "#         super(GraphPredictionModel, self).__init__()\n",
    "#         self.gnn = GCNConv(node_feature_dim, hidden_dim)\n",
    "#         self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "#     def forward(self, x, edge_index):\n",
    "\n",
    "#         # print(f\"input shape: {x.shape}\")\n",
    "\n",
    "#         x = self.gnn(x, edge_index)\n",
    "#         # print(f\"gnn shape: {x.shape}\")\n",
    "\n",
    "#         x = self.fc(x)\n",
    "#         # print(f\"output shape: {x.shape}\")\n",
    "        \n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# input = train_dataset[0][0]\n",
    "# print(input)\n",
    "# num_features = input.x.shape[1]\n",
    "# print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# from torch_geometric.nn import summary\n",
    "# %pip install tabulate\n",
    "\n",
    "# model = GraphPredictionModel(node_feature_dim=num_features, hidden_dim=64, output_dim=2)\n",
    "\n",
    "# print(summary(model, input.x, input.edge_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# output = model(input.x, input.edge_index)\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# # class Node_to_emb(nn.Module):\n",
    "# #     def __init__(self, node_feat_dim=5, node_emb_dim=32):\n",
    "# #         super(Node_to_emb, self).__init__()\n",
    "# #         self.emb = nn.Linear(node_feat_dim, node_emb_dim)\n",
    "\n",
    "# #     def forward(self, nodes):\n",
    "# #         assert nodes.size(-1) == self.emb.in_features, 'wrong input dimension of node features!'\n",
    "# #         return self.emb(nodes)\n",
    "\n",
    "# # class MpLayer(nn.Module):\n",
    "# #     def __init__(self, hidden_dim, activation=nn.ReLU()):\n",
    "# #         super(MpLayer, self).__init__()\n",
    "# #         self.edge_network = nn.Sequential(\n",
    "# #             nn.Linear(2 * hidden_dim + 1, hidden_dim),\n",
    "# #             activation,\n",
    "# #             nn.Linear(hidden_dim, hidden_dim),\n",
    "# #             activation\n",
    "# #         )\n",
    "# #         self.node_network = nn.Sequential(\n",
    "# #             nn.Linear(2 * hidden_dim, hidden_dim),\n",
    "# #             activation,\n",
    "# #             nn.Linear(hidden_dim, hidden_dim)\n",
    "# #         )\n",
    "\n",
    "# #     def forward(self, node_tensor, edge_idx_tensor, edge_attr_tensor):\n",
    "        \n",
    "# #         edge_messages_input = torch.cat([node_tensor[edge_idx_tensor[0, :]], node_tensor[edge_idx_tensor[1, :]]], dim=-1)\n",
    "\n",
    "# #         if edge_attr_tensor is not None:\n",
    "# #             edge_attr_tensor = edge_attr_tensor.unsqueeze(-1)\n",
    "# #             edge_messages_input = torch.cat([edge_messages_input, edge_attr_tensor], dim=-1)\n",
    "\n",
    "# #         edge_messages_output = self.edge_network(edge_messages_input)\n",
    "\n",
    "# #         node_agg_messages = torch.zeros_like(node_tensor).to(node_tensor.device)\n",
    "# #         node_agg_messages = node_agg_messages.scatter_add_(\n",
    "# #             dim=0, index=edge_idx_tensor[1].unsqueeze(-1).expand(-1, node_tensor.size(1)), src=edge_messages_output\n",
    "# #         )\n",
    "\n",
    "# #         node_out = self.node_network(torch.cat([node_tensor, node_agg_messages], dim=-1))\n",
    "# #         return node_out, edge_idx_tensor\n",
    "\n",
    "# # class MpGNN(nn.Module):\n",
    "# #     def __init__(self, node_feat_dim, hidden_dim, activation=nn.ReLU(), num_layers=3):\n",
    "# #         super(MpGNN, self).__init__()\n",
    "# #         self.node_to_emb = Node_to_emb(node_feat_dim, hidden_dim)\n",
    "# #         self.mp_layers = nn.ModuleList([MpLayer(hidden_dim, activation) for _ in range(num_layers)])\n",
    "# #         self.to_pred = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "# #     def forward(self, x, edge_index, edge_attr, batch):\n",
    "# #         x = self.node_to_emb(x)\n",
    "# #         for layer in self.mp_layers:\n",
    "# #             x, edge_index = layer(x, edge_index, edge_attr)\n",
    "\n",
    "# #         out = torch.zeros(batch.max().item() + 1, x.size(1)).to(x.device)\n",
    "# #         idx_aggregate_graph = batch.unsqueeze(-1).expand_as(x)\n",
    "# #         out.scatter_add_(dim=0, index=idx_aggregate_graph, src=x)\n",
    "\n",
    "# #         out = self.to_pred(out)\n",
    "# #         return out\n",
    "\n",
    "# # class GraphPredictionModel(nn.Module):\n",
    "# #     def __init__(self, node_feature_dim, hidden_dim, output_dim, num_layers): # TODO different num_layers for GNN and RNN?\n",
    "# #         super(GraphPredictionModel, self).__init__()\n",
    "# #         self.num_layers = num_layers\n",
    "# #         self.hidden_dim = hidden_dim\n",
    "# #         self.gnn = MpGNN(node_feature_dim, hidden_dim, num_layers=num_layers)\n",
    "# #         self.rnn = nn.GRU(hidden_dim, hidden_dim, num_layers)\n",
    "# #         self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "# #     def forward(self, x, edge_index, edge_attr, batch, h):\n",
    "# #         x = self.gnn(x, edge_index, edge_attr, batch)\n",
    "# #         x, h = self.rnn(x.unsqueeze(0), h)\n",
    "# #         x = self.fc(x.squeeze(0))\n",
    "# #         return x, h\n",
    "\n",
    "# #     def init_hidden(self, batch_size):\n",
    "# #         return torch.zeros(self.num_layers, batch_size, self.hidden_dim)\n",
    "\n",
    "# import torch.nn.init as init\n",
    "\n",
    "# class Node_to_emb(nn.Module):\n",
    "#     def __init__(self, node_feat_dim=14, node_emb_dim=64):\n",
    "#         super(Node_to_emb, self).__init__()\n",
    "#         self.emb = nn.Linear(node_feat_dim, node_emb_dim)\n",
    "#         # init.xavier_uniform_(self.emb.weight)\n",
    "#         init.kaiming_uniform_(self.emb.weight, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "#     def forward(self, nodes):\n",
    "#         assert nodes.size(-1) == self.emb.in_features, 'wrong input dimension of node features!'\n",
    "#         return self.emb(nodes)\n",
    "\n",
    "# class MpLayer(nn.Module):\n",
    "#     def __init__(self, hidden_dim, activation=nn.ReLU()):\n",
    "#         super(MpLayer, self).__init__()\n",
    "#         self.edge_network = nn.Sequential(\n",
    "#             nn.Linear(2 * hidden_dim, hidden_dim),  # No edge_attr, so only 2 * hidden_dim\n",
    "#             activation,\n",
    "#             nn.Linear(hidden_dim, hidden_dim),\n",
    "#             activation\n",
    "#         )\n",
    "#         self.node_network = nn.Sequential(\n",
    "#             nn.Linear(2 * hidden_dim, hidden_dim),\n",
    "#             activation,\n",
    "#             nn.Linear(hidden_dim, hidden_dim)\n",
    "#         )\n",
    "#         # Initialize weights\n",
    "#         for layer in [self.edge_network[0], self.edge_network[2], self.node_network[0], self.node_network[2]]:\n",
    "#             # init.xavier_uniform_(layer.weight)\n",
    "#             init.kaiming_uniform_(layer.weight, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "            \n",
    "\n",
    "#     def forward(self, node_tensor, edge_idx_tensor):\n",
    "#         edge_messages_input = torch.cat([node_tensor[edge_idx_tensor[0, :]], node_tensor[edge_idx_tensor[1, :]]], dim=-1)\n",
    "\n",
    "#         edge_messages_output = self.edge_network(edge_messages_input)\n",
    "\n",
    "#         node_agg_messages = torch.zeros_like(node_tensor).to(node_tensor.device)\n",
    "#         node_agg_messages = node_agg_messages.scatter_add_(\n",
    "#             dim=0, index=edge_idx_tensor[1].unsqueeze(-1).expand(-1, node_tensor.size(1)), src=edge_messages_output\n",
    "#         )\n",
    "\n",
    "#         node_out = self.node_network(torch.cat([node_tensor, node_agg_messages], dim=-1))\n",
    "#         return node_out, edge_idx_tensor\n",
    "\n",
    "# class MpGNN(nn.Module):\n",
    "#     def __init__(self, node_feat_dim, hidden_dim, activation=nn.ReLU(), num_layers=3):\n",
    "#         super(MpGNN, self).__init__()\n",
    "#         self.node_to_emb = Node_to_emb(node_feat_dim, hidden_dim)\n",
    "#         self.mp_layers = nn.ModuleList([MpLayer(hidden_dim, activation) for _ in range(num_layers)])\n",
    "#         # self.to_pred = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "#     def forward(self, x, edge_index):\n",
    "#         x = self.node_to_emb(x)\n",
    "#         for layer in self.mp_layers:\n",
    "#             x, edge_index = layer(x, edge_index)\n",
    "\n",
    "#         # x = self.to_pred(x)\n",
    "#         return x\n",
    "\n",
    "# class GraphPredictionModel(nn.Module):\n",
    "#     def __init__(self, node_feature_dim, hidden_dim, output_dim, num_layers):\n",
    "#         super(GraphPredictionModel, self).__init__()\n",
    "#         self.num_layers = num_layers\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.gnn = MpGNN(node_feature_dim, hidden_dim, num_layers=num_layers)\n",
    "#         self.rnn = nn.GRU(hidden_dim, hidden_dim, num_layers)\n",
    "#         self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "#         # Initialize weights\n",
    "#         # init.xavier_uniform_(self.fc.weight)\n",
    "#         init.kaiming_uniform_(self.fc.weight, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "    \n",
    "#     def forward(self, x, edge_index, h):\n",
    "#         x = self.gnn(x, edge_index)\n",
    "#         x, h = self.rnn(x.unsqueeze(0), h)\n",
    "#         x = self.fc(x.squeeze(0))\n",
    "#         return x, h\n",
    "\n",
    "#     def init_hidden(self, batch_size):\n",
    "#         return torch.zeros(self.num_layers, batch_size, self.hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset[:1]\n",
    "val_dataset = val_dataset[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "node_feature_dim = int(train_dataset[0][0].x.shape[1])  # Example feature dimension\n",
    "print(node_feature_dim)\n",
    "\n",
    "hidden_dim = 512\n",
    "output_dim = 2\n",
    "num_layers = 16\n",
    "\n",
    "learning_rate = 0.0001\n",
    "weight_decay = 1e-5\n",
    "\n",
    "model = GraphPredictionModel(node_feature_dim, hidden_dim, output_dim, num_layers)\n",
    "\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "sequence = train_dataset[0]\n",
    "h = model.init_hidden(sequence[0].x.size(0))\n",
    "print(summary(model, sequence[0].x, sequence[0].edge_index, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "\n",
    "# # Training loop with intermediate prints\n",
    "# num_epochs = 1\n",
    "# losses = []\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "#     for sequence in train_dataset:\n",
    "#         optimizer.zero_grad()\n",
    "#         h = model.init_hidden(sequence[0].x.size(0))\n",
    "        \n",
    "#         for t in range(len(sequence) - 1):\n",
    "#             data_t = sequence[t]\n",
    "#             target = sequence[t + 1].x\n",
    "            \n",
    "#             output, h = model(data_t.x, data_t.edge_index, h)\n",
    "#             loss = criterion(output, target)\n",
    "#             loss.backward(retain_graph=False)  # No need to retain the graph\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             total_loss += loss.item()\n",
    "            \n",
    "#             # Detach hidden state to prevent accumulation of gradients\n",
    "#             h = h.detach()\n",
    "            \n",
    "#             # Print intermediate outputs and target\n",
    "#             if epoch % 10 == 0 and t == 0:  # Print only for the first timestep in the sequence\n",
    "#                 print(f\"Epoch {epoch}, Step {t}\")\n",
    "#                 #print(f\"Output: {output}\")\n",
    "#                 #print(f\"Target: {target}\")\n",
    "#                 print(f\"Loss: {loss.item()}\")\n",
    "    \n",
    "#     avg_loss = total_loss / len(train_dataset)\n",
    "#     losses.append(avg_loss)\n",
    "#     if epoch % 10 == 0:\n",
    "#         print(f'Epoch {epoch}, Loss: {avg_loss}')\n",
    "\n",
    "# Training method\n",
    "def train(model, criterion, optimizer, dataset):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for sequence in tqdm(dataset, desc=\"Training\", leave=False):\n",
    "        optimizer.zero_grad()\n",
    "        h = model.init_hidden(sequence[0].x.size(0))\n",
    "        \n",
    "        for t in range(len(sequence) - 1):\n",
    "            data_t = sequence[t]\n",
    "            target = sequence[t + 1].x[:, :2] # TODO\n",
    "            \n",
    "            output, h = model(data_t.x, data_t.edge_index, h) # Output is x and y coordinates\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward(retain_graph=False)  # No need to retain the graph\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Detach hidden state to prevent accumulation of gradients\n",
    "            h = h.detach()\n",
    "    \n",
    "    avg_loss = total_loss / len(dataset)\n",
    "    return avg_loss\n",
    "\n",
    "# Validation method\n",
    "def validate(model, criterion, dataset):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sequence in tqdm(dataset, desc=\"Validation\", leave=False):\n",
    "            h = model.init_hidden(sequence[0].x.size(0))\n",
    "            \n",
    "            for t in range(len(sequence) - 1):\n",
    "                data_t = sequence[t]\n",
    "                target = sequence[t + 1].x[:, :2] # TODO\n",
    "                \n",
    "                output, h = model(data_t.x, data_t.edge_index, h)\n",
    "                loss = criterion(output, target)\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                # Detach hidden state to prevent accumulation of gradients\n",
    "                h = h.detach()\n",
    "    \n",
    "    avg_loss = total_loss / len(dataset)\n",
    "    return avg_loss\n",
    "\n",
    "# Training loop with validation\n",
    "num_epochs = 1000\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    train_loss = train(model, criterion, optimizer, train_dataset)\n",
    "    val_loss = validate(model, criterion, val_dataset)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model_task2.pth')\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch {epoch + 1}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# Plot the training and validation losses\n",
    "plot_losses(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "model = GraphPredictionModel(node_feature_dim, hidden_dim, output_dim, num_layers)\n",
    "model.load_state_dict(torch.load('best_model_task2.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "def predict_trajectory(model, data, num_steps=40):\n",
    "    \"\"\"\n",
    "    Predicts the trajectory of a system given the initial state.\n",
    "\n",
    "    Parameters:\n",
    "    model (GraphPredictionModel): The model to use for prediction.\n",
    "    data (Data): The initial state of the system.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of Data objects representing the predicted trajectory of the system.\n",
    "\n",
    "    The function first initializes an empty list to store the predicted trajectory. \n",
    "    Then, it iterates over the number of time steps in the trajectory. \n",
    "    For each time step, it uses the model to predict the next state of the system based on the current state. \n",
    "    The predicted state is added to the list of the trajectory. \n",
    "    Finally, the function returns the list of predicted states.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    h = model.init_hidden(data.x.size(0))\n",
    "    trajectory = [data]\n",
    "    for t in range(1, num_steps):\n",
    "        \n",
    "        output, h = model(data.x, data.edge_index, h)\n",
    "\n",
    "        # Add 3 dummy features to the output\n",
    "        output = torch.cat([output, torch.zeros(output.size(0), 3).to(output.device)], dim=-1)\n",
    "\n",
    "        data = Data(x=output, edge_index=data.edge_index)\n",
    "        trajectory.append(data)\n",
    "    return trajectory\n",
    "\n",
    "# test_trajectory = val_dataset[0]\n",
    "test_trajectory = train_dataset[0]\n",
    "print(test_trajectory)\n",
    "prediction = predict_trajectory(model, test_trajectory[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "print(len(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def trajectory_to_numpy(trajectory):\n",
    "    \"\"\"\n",
    "    Converts a trajectory of Data objects to a numpy array of shape (num_steps, num_nodes, num_features).\n",
    "    \"\"\"\n",
    "    num_steps = len(trajectory)\n",
    "    num_nodes = trajectory[0].x.size(0)\n",
    "    num_features = trajectory[0].x.size(1)\n",
    "\n",
    "    trajectory_np = np.zeros((num_steps, num_nodes, num_features))\n",
    "\n",
    "    for i, data in enumerate(trajectory):\n",
    "        # print(i)\n",
    "        trajectory_np[i] = data.x.cpu().detach().numpy()\n",
    "\n",
    "    return trajectory_np\n",
    "\n",
    "test_trajectory_np = trajectory_to_numpy(test_trajectory)\n",
    "prediction_np = trajectory_to_numpy(prediction)\n",
    "prediction_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "energy = np.random.rand(40, 1)\n",
    "\n",
    "plot_trajectory_energy(test_trajectory_np, energy)\n",
    "\n",
    "plot_trajectory_energy(prediction_np, energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "shape = prediction_np.shape\n",
    "random_pred = 20 * np.random.rand(shape[0], shape[1], shape[2])\n",
    "plot_trajectory_energy(random_pred, energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In task 3, you also need to model the influences of the crystal. An example of loading a trajectory can be found below. The trajectory and energy data has the same shape as before, however, data regarding the crystal has been added. Since atoms belonging to the crystal do not move, this data does not have a time dimension when loaded. The shapes of the arrays are as follows:\n",
    "\n",
    "```trajectory```: ```(time, n_bodies, [x, y, v_x, v_y, q])```\n",
    "\n",
    "```energy```: ```(time, 1)```\n",
    "\n",
    "```framework```:```(n_framework_atom, [x, y, q])```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "trajectory, framework, energy = load_trajectory('data/task3/train/trajectory_0.npz', 'task_3')\n",
    "print(f'Trajectory shape: {trajectory.shape}, Framework shape: {framework.shape}, Energy shape: {energy.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code provides an example of how to visualize a trajectory with a crystal. Feel free to modify this code, or write your own function. When evaluating your model in this task, keep in mind that you are only allowed to use the data at t=0 (the black dots in the visualization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "x = trajectory[...,0]\n",
    "y = trajectory[...,1]\n",
    "\n",
    "x_fw = framework[...,0]\n",
    "y_fw = framework[...,1]\n",
    "q_fw = framework[...,2]\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.vlines([0,20],0,20)\n",
    "plt.hlines([0,20],0,20)\n",
    "\n",
    "plt.scatter(x[0], y[0], c='black')\n",
    "\n",
    "for i in range(x.shape[1]):\n",
    "    plt.scatter(x[:,i], y[:,i], s=5)\n",
    "\n",
    "plt.scatter(x_fw, y_fw, c=q_fw, cmap='viridis', s=50)\n",
    "# to also visualize the framework points along the boundaries\n",
    "plt.scatter(x_fw+20, y_fw, c=q_fw, cmap='viridis', s=50)\n",
    "plt.scatter(x_fw, y_fw+20, c=q_fw, cmap='viridis', s=50)\n",
    "plt.scatter(x_fw+20, y_fw+20, c=q_fw, cmap='viridis', s=50)\n",
    "\n",
    "plt.xlim(-1,21)\n",
    "plt.ylim(-1,21)\n",
    "\n",
    "plt.show()\n",
    "plt.figure(figsize=(4,1))\n",
    "plt.plot(energy)\n",
    "plt.xlabel('step')\n",
    "plt.title('System energy over time')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement task 3 below. Feel free to add extra code cells for different components of your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.0)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
