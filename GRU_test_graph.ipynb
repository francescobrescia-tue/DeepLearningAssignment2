{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trajectory(filename, task):\n",
    "    \"\"\"\n",
    "    This function loads a trajectory from a given file and returns the trajectory and energy data. \n",
    "    If the task is 'task_3', it also returns the framework data.\n",
    "\n",
    "    Parameters:\n",
    "    filename (str): The name of the file from which to load the trajectory.\n",
    "    task (str): The task for which the trajectory is being loaded. \n",
    "                This should be one of 'task_1', 'task_2', or 'task_3'.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Depending on the task, the function returns:\n",
    "           - (trajectory, energy) for 'task_1' and 'task_2'\n",
    "           - (trajectory, framework, energy) for 'task_3'\n",
    "    \"\"\"\n",
    "    traj = np.load(filename)\n",
    "    if task == 'task_1' or task == 'task_2':\n",
    "        trajectory = traj['trajectory']\n",
    "        energy = traj['energy']\n",
    "        return trajectory, energy\n",
    "    if task == 'task_3':\n",
    "        trajectory = traj['trajectory']\n",
    "        framework = traj['framework']\n",
    "        energy = traj['energy']\n",
    "        return trajectory, framework, energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimum_image_distance(pos1, pos2, box_length):\n",
    "    \"\"\"\n",
    "    Compute the distance between two points with the minimum image convention.\n",
    "\n",
    "    Parameters:\n",
    "    pos1, pos2: numpy arrays representing the positions of the two points.\n",
    "    box_length: float representing the length of one side of the box.\n",
    "\n",
    "    Returns:\n",
    "    float representing the distance between the two points.\n",
    "    \"\"\"\n",
    "    delta = pos2 - pos1\n",
    "    delta = delta - box_length * np.round(delta / box_length)\n",
    "    return np.sqrt(np.sum(delta**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_from_particles(particles, energy, box_length=20.0, cutoff_value=10.0, task='task_1'):\n",
    "    \"\"\"\n",
    "    This function creates a graph representation of a system of particles for use in graph neural networks. \n",
    "    Each particle is represented as a node in the graph, and edges are created between particles that are within a certain cutoff distance of each other.\n",
    "\n",
    "    Parameters:\n",
    "    particles (numpy.ndarray): A 2D array representing the particles in the system. \n",
    "                               Each row represents a particle, with the first two columns representing the x and y coordinates of the particle, \n",
    "                               and the remaining columns representing additional features of the particle.\n",
    "    energy (float): The energy of the system.\n",
    "    box_length (float, optional): The length of the box in which the particles are contained. \n",
    "                                  This is used to calculate the minimum image distance between particles. Defaults to 20.0.\n",
    "    cutoff_value (float, optional): The maximum distance at which two particles are considered to be connected by an edge. Defaults to 10.0.\n",
    "\n",
    "    Returns:\n",
    "    torch_geometric.data.Data: A Data object representing the graph. \n",
    "                               The node features, edge indices, edge attributes, and energy are stored as attributes of this object.\n",
    "\n",
    "    The function first creates a list of node features and a list of edge indices and attributes. \n",
    "    Then, it converts these lists into PyTorch tensors and creates a Data object from them. \n",
    "    Finally, it validates the Data object to ensure that it is correctly formatted.\n",
    "    \"\"\"\n",
    "\n",
    "    if task == 'task_1':\n",
    "        num_particles = particles.shape[0]\n",
    "        x = particles[:, 2:] # Position is not used as node feature\n",
    "\n",
    "        edge_index = []\n",
    "        edge_attr = []\n",
    "        for i in range(num_particles):\n",
    "            for j in range(num_particles):\n",
    "                if i != j:  # Avoid self-loops\n",
    "\n",
    "                    # Append edge if distance is below cutoff\n",
    "                    pos1 = particles[i, :2]\n",
    "                    pos2 = particles[j, :2]\n",
    "                    distance = minimum_image_distance(pos1, pos2, box_length)\n",
    "                    \n",
    "                    edge_index.append([i, j])\n",
    "                    if distance < cutoff_value: # TODO Per essere corretto non bisognerebbe creare l'edge se la distanza è maggiore del cutoff, ma facendo cosi ci sono errori in alcuni casi limite (annuncio canvas). Ho messo quindi rami con pesi negativi (distanze) per gli edge che non dovrebbero esistere. In questo modo il modello dovrebbe imparare a non considerarli.\n",
    "                        edge_attr.append(distance)\n",
    "                    else:\n",
    "                        edge_attr.append(-1.0) # Use -1.0 as padding value\n",
    "\n",
    "        x = torch.tensor(x, dtype=torch.float)         \n",
    "        edge_index = torch.tensor(edge_index).t().contiguous()\n",
    "        edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "        energy = torch.tensor(energy, dtype=torch.float)\n",
    "\n",
    "        # Create Data object\n",
    "        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=energy)\n",
    "\n",
    "        # Validate data object\n",
    "        data.validate(raise_on_error=True)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    elif task == 'task_2':\n",
    "\n",
    "        num_particles = particles.shape[0]\n",
    "\n",
    "        x = particles[:, :] # Position is used as node feature\n",
    "        energies = np.array([energy]*num_particles)\n",
    "        # Concatenate energy to node features\n",
    "        # x = np.concatenate((x, energies), axis=1) # TODO check\n",
    "\n",
    "        edge_index = []\n",
    "        edge_attr = []\n",
    "        for i in range(num_particles):\n",
    "            for j in range(num_particles):\n",
    "                if i != j:  # Avoid self-loops\n",
    "\n",
    "                    # Append edge if distance is below cutoff\n",
    "                    pos1 = particles[i, :2]\n",
    "                    pos2 = particles[j, :2]\n",
    "                    distance = minimum_image_distance(pos1, pos2, box_length)\n",
    "                    \n",
    "                    edge_index.append([i, j])\n",
    "                    if distance < cutoff_value: # TODO Per essere corretto non bisognerebbe creare l'edge se la distanza è maggiore del cutoff, ma facendo cosi ci sono errori in alcuni casi limite (annuncio canvas). Ho messo quindi rami con pesi negativi (distanze) per gli edge che non dovrebbero esistere. In questo modo il modello dovrebbe imparare a non considerarli.\n",
    "                        edge_attr.append(distance)\n",
    "                    else:\n",
    "                        edge_attr.append(-1.0) # Use -1.0 as padding value\n",
    "\n",
    "        x = torch.tensor(x, dtype=torch.float)         \n",
    "        edge_index = torch.tensor(edge_index).t().contiguous()\n",
    "        edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "        energy = torch.tensor(energy, dtype=torch.float)\n",
    "\n",
    "        # Create Data object\n",
    "        # data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "        data = Data(x=x, edge_index=edge_index) # TODO add also edge_attr\n",
    "\n",
    "        # Validate data object\n",
    "        data.validate(raise_on_error=True)\n",
    "        \n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[4, 5], edge_index=[2, 12])\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "def create_data_point(file_path, box_length=20.0, cutoff_value=10.0, task='task_2', max_len=40):\n",
    "    \"\"\"\n",
    "    This function creates a data point from a given trajectory and energy.\n",
    "\n",
    "    Parameters:\n",
    "    trajectory (numpy.ndarray): A 2D array representing the trajectory of the system. \n",
    "                                The first dimension represents time, and the second dimension represents the x and y coordinates of the particles.\n",
    "    energy (numpy.ndarray): A 1D array representing the energy of the system at each time step.\n",
    "    box_length (float, optional): The length of the box in which the particles are contained. Defaults to 20.0.\n",
    "    cutoff_value (float, optional): The maximum distance at which two particles are considered to be connected by an edge. Defaults to 10.0.\n",
    "\n",
    "    Returns:\n",
    "    torch_geometric.data.Data: A Data object representing the graph of the system at each time step.\n",
    "\n",
    "    The function first creates a list of PyTorch Geometric Data objects, each representing the graph of the system at a different time step. \n",
    "    Then, it returns the first element of the list, which corresponds to the first time step.\n",
    "    \"\"\"\n",
    "    trajectory, energy = load_trajectory(file_path, task)\n",
    "    \n",
    "    # Create Data object with position, velocity, charge and energy for each time step\n",
    "    data_point = []\n",
    "    for i in range(trajectory.shape[0]): # For each time step\n",
    "        particles = trajectory[i]\n",
    "        data_point.append(create_graph_from_particles(particles, energy[i], box_length, cutoff_value, task))\n",
    "            \n",
    "    return data_point\n",
    "\n",
    "data_point = create_data_point('data/task1_2/train/trajectory_0.npz')\n",
    "print(data_point[0])\n",
    "print(len(data_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajectoryDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset for representing a trajectory of a system of particles.\n",
    "\n",
    "    Attributes:\n",
    "    file_paths (list): A list of file paths from which to load the trajectories.\n",
    "    task (str): The task for which the dataset is being created. This should be one of 'task_1', 'task_2', or 'task_3'.\n",
    "    max_len (int): The maximum number of particles in the system.\n",
    "    box_length (float, optional): The length of the box in which the particles are contained. Defaults to 20.0.\n",
    "    cutoff (float, optional): The maximum distance at which two particles are considered to be connected by an edge. Defaults to 10.0.\n",
    "    data_list (list): A list of PyTorch Geometric Data objects, each representing the graph of the system at a different time step.\n",
    "    \"\"\"\n",
    "    def __init__(self, file_paths, task='task_2', max_len=40, box_length=20.0, cutoff=10.0):\n",
    "        \"\"\"\n",
    "        Initializes the TrajectoryDataset with the given file paths, task, maximum number of particles, box length, and cutoff distance.\n",
    "        \"\"\"\n",
    "        self.file_paths = file_paths\n",
    "        self.task = task\n",
    "        self.max_len = max_len\n",
    "        self.box_length = box_length\n",
    "        self.cutoff = cutoff\n",
    "        self.data_list = []\n",
    "        for file_path in tqdm(file_paths):\n",
    "            data_point = create_data_point(file_path, box_length, cutoff, task, max_len)\n",
    "            self.data_list.append(data_point)\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the length of the dataset, i.e., the number of time steps in all trajectories.\n",
    "        \"\"\"\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns the Data object at the given index.\n",
    "        \"\"\"\n",
    "        trajectory=  self.data_list[idx]\n",
    "        X = trajectory[0]\n",
    "        Y = trajectory[1:]\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [00:03<00:00, 185.86it/s]\n",
      "100%|██████████| 180/180 [00:00<00:00, 214.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 720 samples\n",
      "Validation dataset: 180 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "\n",
    "# Define the paths and parameters\n",
    "file_paths = glob.glob('data/task1_2/train/*.npz')\n",
    "\n",
    "max_len = 40  # The maximum length of the trajectories is 40\n",
    "box_length = 20.0  # The length of the simulation box\n",
    "cutoff = 10.0  # The cutoff distance for the edges\n",
    "task = 'task_2'  # The task to perform\n",
    "\n",
    "train_file_paths, val_file_paths = train_test_split(file_paths, test_size=0.2, random_state=0)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TrajectoryDataset(train_file_paths, task, max_len, box_length, cutoff)\n",
    "val_dataset = TrajectoryDataset(val_file_paths, task, max_len, box_length, cutoff)\n",
    "\n",
    "print(f'Train dataset: {len(train_dataset)} samples')\n",
    "print(f'Validation dataset: {len(val_dataset)} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "\n",
    "# class GRUModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(GRUModel, self).__init__()\n",
    "#         self.gru1 = nn.GRU(4, 64, batch_first=True)\n",
    "#         self.repeat_vector = nn.Linear(64, 64)\n",
    "#         self.gru2 = nn.GRU(64, 64, batch_first=True)\n",
    "#         self.fc = nn.Linear(64, 4)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         # Process the initial step\n",
    "#         out, _ = self.gru1(x)\n",
    "#         out = self.repeat_vector(out[:, -1, :]).unsqueeze(1)\n",
    "#         out = out.repeat(1, 39, 1)\n",
    "        \n",
    "#         # Process the repeated vector\n",
    "#         out, _ = self.gru2(out)\n",
    "#         out = self.fc(out)\n",
    "#         return out\n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.gru1 = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        self.repeat_vector = nn.Linear(hidden_size, hidden_size)\n",
    "        self.gru2 = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        #print(x.shape)\n",
    "        # Process the initial step\n",
    "        x = x.unsqueeze(1)  # Add a time step dimension\n",
    "        #print(x.shape)\n",
    "        out, _ = self.gru1(x)\n",
    "        #print(out.shape)\n",
    "        out = self.repeat_vector(out[:, -1, :]).unsqueeze(1)\n",
    "        #print(out.shape)\n",
    "        out = out.repeat(1, 39, 1)\n",
    "        #print(out.shape)\n",
    "        \n",
    "        # Process the repeated vector\n",
    "        out, _ = self.gru2(out)\n",
    "        #print(out.shape)\n",
    "        out = self.fc(out)\n",
    "        #print(out.shape)\n",
    "        out = out.squeeze(0)  # Remove the time step dimension\n",
    "        #print(out.shape)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPNN(nn.Module):\n",
    "    def __init__(self, num_features, hidden_dim):\n",
    "        super(MPNN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        # Ensure x has the correct shape [num_nodes, num_node_features]\n",
    "        # Ensure edge_index is of shape [2, num_edges] for undirected graph\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Example global pooling to aggregate node features into a single graph-level representation\n",
    "        x = torch.mean(x, dim=0, keepdim=True)  # Shape: [1, hidden_dim]\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 5  # Number of features for each node\n",
    "hidden_dim = 64  # Hidden dimension for the GCN layers\n",
    "output_size = 5  # Output size for the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64])\n"
     ]
    }
   ],
   "source": [
    "embedder = MPNN(num_features=num_features, hidden_dim=hidden_dim)\n",
    "predictor = GRUModel(hidden_size=hidden_dim, input_size=hidden_dim, output_size=output_size)\n",
    "\n",
    "graph = train_dataset[0][0]\n",
    "\n",
    "graph_tensor = embedder(graph)\n",
    "print(graph_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 5])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# graph_tensor = graph_tensor.unsqueeze(0)\n",
    "predictions = predictor(graph_tensor)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPNN_GRU(nn.Module):\n",
    "    def __init__(self, num_features, hidden_dim, output_size):\n",
    "        super(MPNN_GRU, self).__init__()\n",
    "        self.embedder = MPNN(num_features, num_features)\n",
    "        self.predictor = GRUModel(input_size=num_features, hidden_size=hidden_dim, output_size=output_size)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x = self.embedder(data)\n",
    "        predictions = self.predictor(x)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 5])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MPNN_GRU(num_features=num_features, hidden_dim=hidden_dim, output_size=output_size)\n",
    "predictions = model(graph)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/720 [00:00<?, ?it/s]/Users/lucamainardi/Documents/TUe/DL/DeepLearningAssignment2/.venv/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([39, 1, 5])) that is different to the input size (torch.Size([39, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "100%|██████████| 720/720 [00:13<00:00, 52.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.0158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [00:13<00:00, 54.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [00:13<00:00, 52.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Loss: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [00:13<00:00, 53.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [00:13<00:00, 55.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for idx in tqdm(range(len(train_dataset))):\n",
    "        X_batch, Y_batch = train_dataset[idx]\n",
    "       \n",
    "        # X_batch = X_batch.unsqueeze(0)  # add a batch dimension TODO\n",
    "\n",
    "        # Compute embeddings of Y_batch\n",
    "        Y_batch = torch.stack([model.embedder(graph) for graph in Y_batch])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch)\n",
    "        # loss = criterion(output, Y_batch.unsqueeze(0))  # add a batch dimension for Y_batch\n",
    "        loss = criterion(output, Y_batch) # TODO\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_loss = epoch_loss / len(train_dataset)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trajectory(trajectory):\n",
    "    \"\"\"\n",
    "    This function plots the trajectory of a system and its energy over time.\n",
    "\n",
    "    Parameters:\n",
    "    trajectory (numpy.ndarray): A 2D array representing the trajectory of the system. \n",
    "                                The first dimension represents time, and the second dimension represents the x and y coordinates.\n",
    "    energy (numpy.ndarray): A 1D array representing the energy of the system at each time step.\n",
    "\n",
    "    The function first plots the trajectory on a 2D grid, with the x and y coordinates on the x and y axes respectively. \n",
    "    The initial position is marked in black. The trajectory is represented by a scatter plot, with each point representing the position at a different time step.\n",
    "\n",
    "    Then, the function plots the energy of the system over time on a separate graph. The x-axis represents the time step, and the y-axis represents the energy.\n",
    "    \"\"\"\n",
    "    \n",
    "    x = trajectory[...,0]\n",
    "    y = trajectory[...,1]\n",
    "\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.vlines([0,20],0,20)\n",
    "    plt.hlines([0,20],0,20)\n",
    "\n",
    "    plt.scatter(x[0], y[0], c='black')\n",
    "\n",
    "    for i in range(x.shape[1]):\n",
    "        plt.scatter(x[:,i], y[:,i], s=5)\n",
    "\n",
    "    plt.xlim(-1,21)\n",
    "    plt.ylim(-1,21)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 4, 5)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_trajectory = load_trajectory('data/task1_2/train/trajectory_0.npz', 'task_2')[0]\n",
    "test_trajectory.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[4, 5], edge_index=[2, 12])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_graph = create_graph_from_particles(test_trajectory[0], 0.0, box_length=20.0, cutoff_value=10.0, task='task_2')\n",
    "test_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = test_graph.x\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 5])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(test_graph)\n",
    "predictions.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
